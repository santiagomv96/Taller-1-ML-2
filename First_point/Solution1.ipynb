{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_matrix = np.random.rand(np.random.randint(10), np.random.randint(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "matrix range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix range 10\n",
      "matrix trace 4.371869946614666\n"
     ]
    }
   ],
   "source": [
    "matrix_range=np.linalg.matrix_rank(random_matrix)\n",
    "print(f\"matrix range {matrix_range}\")\n",
    "if random_matrix.shape[0]==random_matrix.shape[1]:   \n",
    "    trace = sum([random_matrix[i][i] for i in range(random_matrix.shape[0])]) \n",
    "    print(f\"matrix trace {trace}\")\n",
    "else:\n",
    "    print(f\"non squared matrix\")\n",
    "    raise ValueError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix determinant 0.0019124116055781355\n"
     ]
    }
   ],
   "source": [
    "if random_matrix.shape[0]==random_matrix.shape[1]:    \n",
    "    det_matrix = np.linalg.det(random_matrix)\n",
    "    print(f\"Matrix determinant {det_matrix}\")\n",
    "else:\n",
    "    print(f\"non squared matrix\")\n",
    "    raise ValueError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert Matrix:\n",
    "If the determinant of the matrix is different from zero, it is possible to obtain an inverted matrix from the original. In this case, we have used the NumPy method linalg.inv. However, the classical way is to concatenate the identity matrix with the original and try to obtain the original matrix in the identity by performing row operations. The resulting matrix on the right-hand side is the inverted matrix of the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverse matrix [[0.77045168 0.74285783 0.87936037 0.72373322 0.18027506 0.24846673\n",
      "  0.81062298 0.30020942 0.81890014 0.57669329]\n",
      " [0.31980689 0.80612433 0.43795335 0.63654606 0.11035551 0.30437888\n",
      "  0.09477824 0.61072263 0.95750917 0.33867673]\n",
      " [0.40620427 0.20738335 0.26205303 0.33400759 0.39130017 0.58833532\n",
      "  0.30104363 0.00227444 0.14484982 0.53140051]\n",
      " [0.08439596 0.43171034 0.86159884 0.23818382 0.70718498 0.56533572\n",
      "  0.45597412 0.27815281 0.97932126 0.88286246]\n",
      " [0.70286798 0.95440943 0.08537684 0.40193239 0.93290451 0.69488482\n",
      "  0.21506951 0.74834863 0.06715474 0.77000108]\n",
      " [0.16378878 0.10342662 0.21008218 0.24342095 0.19109987 0.83961549\n",
      "  0.90100314 0.70180555 0.26524196 0.39511751]\n",
      " [0.2962619  0.95498273 0.20969668 0.44427089 0.91130909 0.6959967\n",
      "  0.1052188  0.7253469  0.93760864 0.87110158]\n",
      " [0.47959616 0.53118213 0.29806525 0.99533967 0.59772455 0.01555442\n",
      "  0.4133806  0.00532946 0.35411824 0.57516571]\n",
      " [0.05817359 0.30254041 0.03278661 0.49862864 0.96624733 0.82176394\n",
      "  0.2427705  0.75193366 0.26742205 0.39179134]\n",
      " [0.7005212  0.40361526 0.03431011 0.82568056 0.70459471 0.85686698\n",
      "  0.62636776 0.53043157 0.28753817 0.14456676]]\n"
     ]
    }
   ],
   "source": [
    "if det_matrix==0:\n",
    "    raise ValueError\n",
    "else:\n",
    "    inv_A = np.linalg.inv(random_matrix)\n",
    "\n",
    "print(f\"inverse matrix {random_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape ingevectors (2, 2) \n",
      " Ingevectors Matrix @ Matrix'T \n",
      " [[ 0.81975706 -0.57271142]\n",
      " [ 0.57271142  0.81975706]] \n",
      "\n",
      "shape ingevectors (5, 5) \n",
      " Ingevectors Matrix'T @ Matrix \n",
      " [[-0.12620567+0.j          0.28212214+0.j          0.10958583-0.40560449j\n",
      "   0.10958583+0.40560449j  0.22290638+0.j        ]\n",
      " [-0.43081373+0.j          0.02865324+0.j         -0.73916438+0.j\n",
      "  -0.73916438-0.j          0.11209969+0.j        ]\n",
      " [-0.3570124 +0.j         -0.67212042+0.j          0.03367587+0.15073912j\n",
      "   0.03367587-0.15073912j  0.60771341+0.j        ]\n",
      " [-0.54073846+0.j         -0.32794754+0.j          0.31857782-0.25519875j\n",
      "   0.31857782+0.25519875j -0.73477822+0.j        ]\n",
      " [-0.61531759+0.j          0.60024215+0.j          0.19554428+0.21999962j\n",
      "   0.19554428-0.21999962j  0.16891356+0.j        ]]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(random_matrix @ random_matrix.T)\n",
    "print(f\"shape ingevectors {eigenvectors.shape} \\n Ingevectors Matrix @ Matrix'T \\n {eigenvectors} \\n\")\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eig(random_matrix.T @ random_matrix)\n",
    "print(f\"shape ingevectors {eigenvectors.shape} \\n Ingevectors Matrix'T @ Matrix \\n {eigenvectors}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we compute the matrix product between the original matrix and its transpose, it is clear that the resulting matrix is square, but in different ways, since its order will change if the original matrix is not square. The eigenvectors will always create a square matrix, with each eigenvector having an associated eigenvalue. As the eigenvalue gets bigger, the eigenvector retains more variance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
